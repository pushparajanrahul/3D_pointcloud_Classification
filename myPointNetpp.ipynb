{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "23824b33-e435-496b-910a-f8acee336fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import random\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e3db532-c6e5-4bc7-a255-9e96f5b85a69",
   "metadata": {},
   "source": [
    "## <ins>Exploratory Data Analysis - Object File format for 3D Shapes</ins>\n",
    "\n",
    "### 1. Identifying the Classes and moving into Hashmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e79fafee-20df-45e6-b10e-8fddcb1879b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'airplane',\n",
       " 1: 'bathtub',\n",
       " 2: 'bed',\n",
       " 3: 'bench',\n",
       " 4: 'bookshelf',\n",
       " 5: 'bottle',\n",
       " 6: 'bowl',\n",
       " 7: 'car',\n",
       " 8: 'chair',\n",
       " 9: 'cone',\n",
       " 10: 'cup',\n",
       " 11: 'curtain',\n",
       " 12: 'desk',\n",
       " 13: 'door',\n",
       " 14: 'dresser',\n",
       " 15: 'flower_pot',\n",
       " 16: 'glass_box',\n",
       " 17: 'guitar',\n",
       " 18: 'keyboard',\n",
       " 19: 'lamp',\n",
       " 20: 'laptop',\n",
       " 21: 'mantel',\n",
       " 22: 'monitor',\n",
       " 23: 'night_stand',\n",
       " 24: 'person',\n",
       " 25: 'piano',\n",
       " 26: 'plant',\n",
       " 27: 'radio',\n",
       " 28: 'range_hood',\n",
       " 29: 'sink',\n",
       " 30: 'sofa',\n",
       " 31: 'stairs',\n",
       " 32: 'stool',\n",
       " 33: 'table',\n",
       " 34: 'tent',\n",
       " 35: 'toilet',\n",
       " 36: 'tv_stand',\n",
       " 37: 'vase',\n",
       " 38: 'wardrobe',\n",
       " 39: 'xbox'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = Path(\"/scratch/rpushpar/Datasets/ModelNet40/raw\")\n",
    "\n",
    "classes = {i:folder for i, folder in enumerate(sorted(os.listdir(path)))}\n",
    "classes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "158fdc88-26df-4d26-972b-82ec62ea5a2a",
   "metadata": {},
   "source": [
    "### 2. Exploring a sample datapoints (.OFF file) and extracting it's Vertices and Faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d3985d7f-56ae-4340-b38f-ebe6d13a78e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def OFF_data_representer(file):\n",
    "    # Reading the first line of the OFF file\n",
    "    OFF_header = file.readline().strip()\n",
    "\n",
    "    # Checking if the above read content is OFF indicating an Object File Format file\n",
    "    if OFF_header == \"OFF\":\n",
    "        # If yes, then extract the vertices and faces count listed in the second line\n",
    "        n_vertices, n_faces, _ = [int(s) for s in file.readline().strip().split(' ')]\n",
    "    else:\n",
    "        # Elseif the info is along the first line, get the vertices and faces count\n",
    "        n_vertices, n_faces, _ = [int(s) for s in OFF_header[3:].strip().split(' ')]\n",
    "\n",
    "    \n",
    "    # In a loop for total number of vertices, get the vertices as a List[List]\n",
    "    vertices = [[float(v) for v in file.readline().strip().split(' ')] for i_vertice in range(n_vertices)]\n",
    "\n",
    "    # In a loop for total number of faces, get the faces as a List[List]\n",
    "    faces = [[int(f) for f in file.readline()[1:].strip().split(' ')] for i_faces in range(n_faces)]\n",
    "\n",
    "    return vertices, faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "101aadc9-653e-40a4-ba23-f9d6cbc986e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([[20.967, -26.1154, 46.5444],\n",
       "  [21.0619, -26.091, 46.5031],\n",
       "  [-83.1524, -52.8062, 91.8328],\n",
       "  [20.967, -26.1154, 46.5444],\n",
       "  [0.572407, -48.35, 93.2093]],\n",
       " [[24, 25, 26], [25, 24, 27], [28, 29, 30], [31, 30, 29], [27, 32, 25]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Open a sample file to extract the vertices and faces\n",
    "with open(path/\"airplane/train/airplane_0001.off\", \"r\") as f:\n",
    "    vertices, faces = OFF_data_representer(f)\n",
    "\n",
    "# Display the first 5 vertices and faces\n",
    "vertices[0:5], faces[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdca8080-3187-45df-8bba-fc208744c6ad",
   "metadata": {},
   "source": [
    "### 3. Displaying the sample 3D shape "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56cc378d-008f-4dc4-8bf0-bade88f681cc",
   "metadata": {},
   "source": [
    "#### 3.1. 3D Mesh Display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "89aaaa5f-87fb-4dff-9444-1ef8f98c497c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making the vertices and faces as numpy array's to use in Plotly function\n",
    "i, j, k = np.array(faces).T\n",
    "x, y, z = np.array(vertices).T\n",
    "\n",
    "# Using Mesh3d from Plotly, we take each vector in space and its angles and plot them\n",
    "data = go.Mesh3d(x=x, y=y, z=z, i=i, j=j, k=k, color='lightpink', opacity=0.5)\n",
    "fig = go.Figure(data)\n",
    "#fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14da99c6-b69e-4c3d-9588-62c2ddba0a73",
   "metadata": {},
   "source": [
    "#### 3.2. 3D Scatter Display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "698b17b2-00fa-48eb-bcf1-85a84d4b4b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Scatter3d from Plotly, we take each vector in space and its angles and plot them\n",
    "data = go.Scatter3d(x=x, y=y, z=z, mode='markers', marker=dict(size=1, color=z, colorscale='Viridis', opacity=0.5))\n",
    "fig = go.Figure(data)\n",
    "#fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e677b63-15d2-4af4-9a27-86390e7fa85d",
   "metadata": {},
   "source": [
    "## <ins>Data Conversion - Vertices and Faces to Point Cloud Data</ins>\n",
    "\n",
    "### 1. Point Sampler\n",
    "\n",
    "**Point Sampler** is mainly used to **convert mesh data (vertices and faces) into a point cloud** by sampling points inside the triangles that make up the mesh. This is done by generating points using **barycentric coordinates**. \n",
    "**Downsampling** can also be an aspect of Point Sampling, where the number of points is reduced, but the goal is to preserve the shape and geometry of the 3D object in the new point cloud representation. It ensures that the **3D shape is still intact** by sampling points **inside the faces**, thus maintaining a proper representation of the object for tasks such as 3D classification or segmentation.\n",
    "\n",
    "Currently, we have only the vertices(cordinates of each point in space (*x,y,z*) and the faces which provides information about which 3 vertices forming a triangle when arranged would provide the shape of the corresponding 3D object. Given this, we aim to construct the point cloud data for each object by mathematically modelling it. To do so, we folow the below steps:\n",
    "\n",
    "**Triangle Area** : Calculates the area of a triangle defined by three points (pt1, pt2, pt3) in 3D space.\n",
    "\n",
    "1. First, we calculate the distance between each pair of vertices (side_a, side_b, side_c) using np.linalg.norm, which computes the Euclidean distance between two points.\n",
    "2. Then it calculates the semi-perimeter (s) and uses Heronâ€™s formula to compute the area of the triangle.\n",
    "3. This area is useful in weighted sampling, where larger triangles will have a higher probability of being sampled\n",
    "\n",
    "**Sample Point** : Samples a random point inside a triangle defined by pt1, pt2, and pt3.\n",
    "\n",
    "1. Two random numbers (s, t) are generated and sorted to determine the relative positions of the point within the triangle.\n",
    "2. The lambda function f(i) computes the coordinates of the sampled point based on the barycentric interpolation formula, which ensures the sampled point lies inside the triangle.\n",
    "\n",
    "The *__call__* function receives the vertices and faces as arguments. Moving forward: \n",
    "- The method first computer the area of each triangle\n",
    "- It samples the triangle based on the area using random.choices (which selects traingles with higher area more frequently)\n",
    "- After selecting the triangle the corresponsing triangle vertices are passed into Sample Point Method, resulting the sample points.\n",
    "- The sample points are stored in a sample_point numpy array with shape (output_size, 3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "080286c1-0bd5-49d0-8c95-ed1f39bf894d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PointSampler(object):\n",
    "    def __init__(self, output_size):\n",
    "        assert isinstance(output_size, int)\n",
    "        self.output_size = output_size\n",
    "    \n",
    "    def triangle_area(self, pt1, pt2, pt3):\n",
    "        side_a = np.linalg.norm(pt1 - pt2)\n",
    "        side_b = np.linalg.norm(pt2 - pt3)\n",
    "        side_c = np.linalg.norm(pt3 - pt1)\n",
    "        s = 0.5 * ( side_a + side_b + side_c)\n",
    "        return max(s * (s - side_a) * (s - side_b) * (s - side_c), 0)**0.5\n",
    "\n",
    "    def sample_point(self, pt1, pt2, pt3):\n",
    "        # barycentric coordinates on a triangle\n",
    "        # https://mathworld.wolfram.com/BarycentricCoordinates.html\n",
    "\n",
    "        ''' \n",
    "            In a triangle with vertices pt1, pt2 and pt3, a point P is called Barycentric Coordinate such that:\n",
    "                                            P = Î»1.pt1 + Î»2.pt2 + Î»3.pt3     , where Î»1 + Î»2 + Î»3 = 1\n",
    "            \n",
    "            Now, consider a triangle with the following vertices,\n",
    "                                            pt1=(0,0,0)\n",
    "                                            pt2=(1,0,0)\n",
    "                                            pt3=(0,1,0)\n",
    "            \n",
    "            Let's say the random values s=0.2 and t=0.6 such that 0 < s < 1 and 0 < t < 1,\n",
    "\n",
    "            The barycentric coordinates would be:\n",
    "                                            Î»1 = s = 0.2\n",
    "                                            Î»2 = (s-t) = 0.2\n",
    "                                            Î»3 = (1-t) = 0.6                 ,where Î»1 = s, Î»2 = (t-s), Î»3 = (1-t) such that Î»1 + Î»2 + Î»3 = 1\n",
    "\n",
    "            Using the lambda function to compute the point:\n",
    "            \n",
    "                                x=s.x1 + (t-s).x2 + (1-t).x3\n",
    "                                x=sâ‹…0  + (tâˆ’s)â‹…1   + (1âˆ’t)â‹…0  =0.2â‹…0+(0.6âˆ’0.2)â‹…1+(1âˆ’0.6)â‹…0=0.4\n",
    "                                \n",
    "                                y=s.y1 + (s-t).y2 + (1-t).y3\n",
    "                                y=sâ‹…0   +(tâˆ’s)â‹…0   +(1âˆ’t)â‹…1   =0.2â‹…0+(0.6âˆ’0.2)â‹…0+(1âˆ’0.6)â‹…1=0.4\n",
    "\n",
    "                                z=s.z1 + (t-s).z2 + (1-t).z3\n",
    "                                z=sâ‹…0   +(tâˆ’s)â‹…0   +(1âˆ’t)â‹…0   =0\n",
    "\n",
    "            Thus, the random point inside the triangle is (0.4, 0.4, 0)\n",
    "        '''\n",
    "\n",
    "        \n",
    "        # Generate two random float's between 0 and 1 (excluding 1)\n",
    "        s, t = sorted([random.random(), random.random()])\n",
    "\n",
    "        \n",
    "        f = lambda i: s * pt1[i] + (t-s)*pt2[i] + (1-t)*pt3[i]\n",
    "        return (f(0), f(1), f(2))\n",
    "        \n",
    "    \n",
    "    def __call__(self, mesh):\n",
    "        vertices, faces = mesh\n",
    "        vertices = np.array(vertices)\n",
    "        areas = np.zeros((len(faces)))\n",
    "\n",
    "        for i in range(len(areas)):\n",
    "            areas[i] = (self.triangle_area(vertices[faces[i][0]],\n",
    "                                           vertices[faces[i][1]],\n",
    "                                           vertices[faces[i][2]]))\n",
    "            \n",
    "        sampled_faces = (random.choices(faces, \n",
    "                                      weights=areas,\n",
    "                                      cum_weights=None,\n",
    "                                      k=self.output_size))\n",
    "        \n",
    "        sampled_points = np.zeros((self.output_size, 3))\n",
    "\n",
    "        for i in range(len(sampled_faces)):\n",
    "            sampled_points[i] = (self.sample_point(vertices[sampled_faces[i][0]],\n",
    "                                                   vertices[sampled_faces[i][1]],\n",
    "                                                   vertices[sampled_faces[i][2]]))\n",
    "        \n",
    "        return sampled_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d0029177-bd85-4637-90cc-c71d93c858ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "pointcloud = PointSampler(4000)((vertices, faces))\n",
    "x, y, z = pointcloud.T\n",
    "data = go.Scatter3d(x=x, y=y, z=z, mode='markers', marker=dict(size=1, color=z, colorscale='Viridis', opacity=0.5))\n",
    "fig= go.Figure(data)\n",
    "#fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caab130d-61ca-411b-b62c-842a0c5f5515",
   "metadata": {},
   "source": [
    "*Inference*:\n",
    "\n",
    "Thus, The **PointSampler class** is **not performing random reductions** of an existing point cloud, but instead it is **sampling points** from the **mesh's faces** to generate **a new point cloud**.\n",
    "The downsampling helps **reduce the complexity of the data** (e.g., from a mesh with a large number of faces to a fixed number of points) while still keeping the surface of the object intact for further processing (such as training a machine learning model)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29fbbd50-5c0a-47c0-b2d5-b1226a1db18e",
   "metadata": {},
   "source": [
    "## <ins>Data Augmentation</ins>\n",
    "\n",
    "### 1. Normalize Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "92da275f-2bce-4668-9716-86b262192462",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Normalize(object):\n",
    "    def __call__(self, pointcloud):\n",
    "        assert len(pointcloud.shape)==2\n",
    "        \n",
    "        norm_pointcloud = pointcloud - np.mean(pointcloud, axis=0) \n",
    "        norm_pointcloud /= np.max(np.linalg.norm(norm_pointcloud, axis=1))\n",
    "\n",
    "        return  norm_pointcloud"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7923e497-717f-4c1b-8fdd-01bbf617c808",
   "metadata": {},
   "source": [
    "### 2. Random Rotation along Z-axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "af84dcdf-8793-410a-80c7-422fc3ed3f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandRotation_z(object):\n",
    "    def __call__(self, pointcloud):\n",
    "        assert len(pointcloud.shape)==2\n",
    "\n",
    "        theta = random.random() * 2. * math.pi\n",
    "        rot_matrix = np.array([[ math.cos(theta), -math.sin(theta),    0],\n",
    "                               [ math.sin(theta),  math.cos(theta),    0],\n",
    "                               [0,                             0,      1]])\n",
    "        \n",
    "        rot_pointcloud = rot_matrix.dot(pointcloud.T).T\n",
    "        return  rot_pointcloud"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdc8a647-7f8d-46f7-a3c9-470b1c367b4b",
   "metadata": {},
   "source": [
    "### 3. Random Noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e07c2516-43bc-4be4-a05a-cdbd1102d311",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomNoise(object):\n",
    "    def __call__(self, pointcloud):\n",
    "        assert len(pointcloud.shape)==2\n",
    "\n",
    "        noise = np.random.normal(0, 0.02, (pointcloud.shape))\n",
    "    \n",
    "        noisy_pointcloud = pointcloud + noise\n",
    "        return  noisy_pointcloud"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ece971fa-d67c-4018-a17b-5b788558d3cf",
   "metadata": {},
   "source": [
    "### 4. Convert the Point Augmented Data Point Cloud to Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "58cbf947-2f79-4e53-bcc5-59fe7ddd9fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ToTensor(object):\n",
    "    def __call__(self, pointcloud):\n",
    "        assert len(pointcloud.shape)==2\n",
    "\n",
    "        return torch.from_numpy(pointcloud)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52f838dc-2c5d-4a8c-90fe-8a6066965515",
   "metadata": {},
   "source": [
    "## <ins>Dataset Preparation</ins>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46f29715-3512-4c0f-a3f2-ac52e9a12102",
   "metadata": {},
   "source": [
    "### 1. Data Transform Method's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dd525613-6414-4b9f-ab78-b4ec8610a1bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selected except Training Dataset (Validation and Testing)\n",
    "def default_transforms():\n",
    "    return transforms.Compose([\n",
    "        PointSampler(1024),\n",
    "        Normalize(),\n",
    "        ToTensor()])\n",
    "\n",
    "# Selected only for Training Dataset\n",
    "def train_transforms():\n",
    "    return transforms.Compose([\n",
    "        PointSampler(1024),\n",
    "        Normalize(),\n",
    "        RandRotation_z(),\n",
    "        RandomNoise(),\n",
    "        ToTensor()])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8da40b6-918b-4e60-9f8e-7031ae52cef0",
   "metadata": {},
   "source": [
    "### 2. Data Preprocessing Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a3d57952-a508-42f1-84ab-784efcfa6837",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PointCloudData(Dataset):\n",
    "    def __init__(self, root_dir, valid=False, folder=\"train\", transform=default_transforms()):\n",
    "        self.root_dir = root_dir\n",
    "        folders = [dir for dir in sorted(os.listdir(root_dir)) if os.path.isdir(root_dir/dir)]\n",
    "        self.classes = {folder: i for i, folder in enumerate(folders)}\n",
    "        self.transforms = transform if not valid else default_transforms()\n",
    "        self.valid = valid\n",
    "        self.files = []\n",
    "        for category in self.classes.keys():\n",
    "            new_dir = root_dir/Path(category)/folder\n",
    "            for file in os.listdir(new_dir):\n",
    "                if file.endswith('.off'):\n",
    "                    sample = {}\n",
    "                    sample['pcd_path'] = new_dir/file\n",
    "                    sample['category'] = category\n",
    "                    self.files.append(sample)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "\n",
    "    def __preproc__(self, file):\n",
    "        verts, faces = OFF_data_representer(file)\n",
    "        if self.transforms:\n",
    "            pointcloud = self.transforms((verts, faces))\n",
    "        return pointcloud\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        pcd_path = self.files[idx]['pcd_path']\n",
    "        category = self.files[idx]['category']\n",
    "        with open(pcd_path, 'r') as f:\n",
    "            pointcloud = self.__preproc__(f)\n",
    "        return {'pointcloud': pointcloud, \n",
    "                'category': self.classes[category]}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99728871-e4e2-4ef0-aff4-106871e4c32d",
   "metadata": {},
   "source": [
    "### 3. Dataset definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "59cf632f-9ee1-4e69-95e2-8fd7730f721b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = PointCloudData(path, transform=train_transforms())\n",
    "valid_ds = PointCloudData(path, valid=True, folder='test', transform=default_transforms())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fdefa9c9-f952-42d9-9cfe-67f83cb9834c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset size:  9843\n",
      "Valid dataset size:  2468\n",
      "Number of classes:  40\n",
      "Sample pointcloud shape:  torch.Size([1024, 3])\n",
      "Class:  airplane\n"
     ]
    }
   ],
   "source": [
    "print('Train dataset size: ', len(train_ds))\n",
    "print('Valid dataset size: ', len(valid_ds))\n",
    "print('Number of classes: ', len(train_ds.classes))\n",
    "print('Sample pointcloud shape: ', train_ds[0]['pointcloud'].size())\n",
    "print('Class: ', classes[train_ds[0]['category']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "091e1262-7128-4800-b4b2-8a3c95029ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(dataset=train_ds, batch_size=32, shuffle=True)\n",
    "valid_loader = DataLoader(dataset=valid_ds, batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7853136c-60d7-4ef1-a875-4773f568fa71",
   "metadata": {},
   "source": [
    "## <ins>Model Definition</ins>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8f2803fc-0c4e-4e7d-b634-895893099ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class PointNetSetAbstraction(nn.Module):\n",
    "    def __init__(self, npoint, radius, nsample, in_channel, mlp, group_all):\n",
    "        super(PointNetSetAbstraction, self).__init__()\n",
    "        self.npoint = npoint\n",
    "        self.radius = radius\n",
    "        self.nsample = nsample\n",
    "        self.mlp_convs = nn.ModuleList()\n",
    "        self.mlp_bns = nn.ModuleList()\n",
    "        last_channel = in_channel\n",
    "        for out_channel in mlp:\n",
    "            self.mlp_convs.append(nn.Conv2d(last_channel, out_channel, 1))\n",
    "            self.mlp_bns.append(nn.BatchNorm2d(out_channel))\n",
    "            last_channel = out_channel\n",
    "        self.group_all = group_all\n",
    "\n",
    "    def forward(self, xyz, points=None):\n",
    "        # if self.npoint is None:  \n",
    "        #     new_xyz = None\n",
    "        #     new_points = points.unsqueeze(2) if points is not None else xyz.unsqueeze(2)\n",
    "        #     for i, conv in enumerate(self.mlp_convs):\n",
    "        #         bn = self.mlp_bns[i]\n",
    "        #         new_points = F.relu(bn(conv(new_points)))\n",
    "        #     new_points = torch.max(new_points, -1)[0]\n",
    "        # else:\n",
    "        #     # Sample and group points\n",
    "        #     new_xyz, new_points = self.sample_and_group(xyz, points)\n",
    "        #     new_points = new_points.permute(0, 3, 1, 2)  # (B, N, C, K) -> (B, C, N, K)\n",
    "        #     for i, conv in enumerate(self.mlp_convs):\n",
    "        #         bn = self.mlp_bns[i]\n",
    "        #         new_points = F.relu(bn(conv(new_points)))\n",
    "        #     new_points = torch.max(new_points, -1)[0]  # Max pooling\n",
    "        # return new_xyz, new_points\n",
    "        xyz = xyz.permute(0, 2, 1)\n",
    "        if points is not None:\n",
    "            points = points.permute(0, 2, 1)\n",
    "\n",
    "        if self.group_all:\n",
    "            new_xyz, new_points = self.sample_and_group_all(xyz, points)\n",
    "        else:\n",
    "            new_xyz, new_points = self.sample_and_group(self.npoint, self.radius, self.nsample, xyz, points)\n",
    "        # new_xyz: sampled points position data, [B, npoint, C]\n",
    "        # new_points: sampled points data, [B, npoint, nsample, C+D]\n",
    "        new_points = new_points.permute(0, 3, 2, 1) # [B, C+D, nsample,npoint]\n",
    "        for i, conv in enumerate(self.mlp_convs):\n",
    "            bn = self.mlp_bns[i]\n",
    "            new_points =  F.relu(bn(conv(new_points)))\n",
    "\n",
    "        new_points = torch.max(new_points, 2)[0]\n",
    "        new_xyz = new_xyz.permute(0, 2, 1)\n",
    "        return new_xyz, new_points       \n",
    "\n",
    "    def sample_and_group(self, npoint, radius, nsample, xyz, points, returnfps=False):\n",
    "        B, N, C = xyz.shape\n",
    "        S = self.npoint\n",
    "        fps_idx = self.farthest_point_sample(xyz, S)\n",
    "        new_xyz = self.index_points(xyz, fps_idx)\n",
    "        idx = self.ball_query(self.radius, self.nsample, xyz, new_xyz)\n",
    "        grouped_xyz = self.index_points(xyz, idx)\n",
    "        grouped_xyz_norm = grouped_xyz - new_xyz.view(B, S, 1, C)\n",
    "        if points is not None:\n",
    "            grouped_points = self.index_points(points, idx)\n",
    "            new_points = torch.cat([grouped_xyz_norm, grouped_points], dim=-1)\n",
    "        else:\n",
    "            new_points = grouped_xyz_norm\n",
    "        return new_xyz, new_points\n",
    "\n",
    "    def sample_and_group_all(self, xyz, points):\n",
    "        \"\"\"\n",
    "        Input:\n",
    "            xyz: input points position data, [B, N, 3]\n",
    "            points: input points data, [B, N, D]\n",
    "        Return:\n",
    "            new_xyz: sampled points position data, [B, 1, 3]\n",
    "            new_points: sampled points data, [B, 1, N, 3+D]\n",
    "        \"\"\"\n",
    "        device = xyz.device\n",
    "        B, N, C = xyz.shape\n",
    "        new_xyz = torch.zeros(B, 1, C).to(device)\n",
    "        grouped_xyz = xyz.view(B, 1, N, C)\n",
    "        if points is not None:\n",
    "            new_points = torch.cat([grouped_xyz, points.view(B, 1, N, -1)], dim=-1)\n",
    "        else:\n",
    "            new_points = grouped_xyz\n",
    "        return new_xyz, new_points\n",
    "\n",
    "    def farthest_point_sample(self, xyz, npoint):\n",
    "        B, N, C = xyz.shape\n",
    "        centroids = torch.zeros(B, npoint, dtype=torch.long).to(xyz.device)\n",
    "        distance = torch.ones(B, N).to(xyz.device) * 1e10\n",
    "        farthest = torch.randint(0, N, (B,), dtype=torch.long).to(xyz.device)\n",
    "        batch_indices = torch.arange(B, dtype=torch.long).to(xyz.device)\n",
    "        for i in range(npoint):\n",
    "            centroids[:, i] = farthest\n",
    "            #centroid = xyz[batch_indices, farthest, :].view(B, 1, C)\n",
    "            centroid = xyz[batch_indices, farthest, :].view(B, 1, 3)\n",
    "            dist = torch.sum((xyz - centroid) ** 2, -1)\n",
    "            mask = dist < distance\n",
    "            distance[mask] = dist[mask]\n",
    "            farthest = torch.max(distance, -1)[1]\n",
    "        return centroids\n",
    "\n",
    "    def index_points(self, points, idx):\n",
    "        B = points.shape[0]\n",
    "        view_shape = list(idx.shape)\n",
    "        view_shape[1:] = [1] * (len(view_shape) - 1)\n",
    "        repeat_shape = list(idx.shape)\n",
    "        repeat_shape[0] = 1\n",
    "        batch_indices = torch.arange(B, dtype=torch.long).to(points.device).view(view_shape).repeat(repeat_shape)\n",
    "        new_points = points[batch_indices, idx, :]\n",
    "        return new_points\n",
    "\n",
    "    def ball_query(self, radius, nsample, xyz, new_xyz):\n",
    "        B, N, C = xyz.shape\n",
    "        _,S,_ = new_xyz.shape\n",
    "        sqrdists = self.square_distance(new_xyz, xyz)\n",
    "        group_idx = torch.arange(N, dtype=torch.long).to(xyz.device).view(1, 1, N).repeat([B, S, 1])\n",
    "        group_idx[sqrdists > radius ** 2] = N  \n",
    "        group_idx = group_idx.sort(dim=-1)[0][:, :, :nsample]\n",
    "        \n",
    "        group_first = group_idx[:, :, 0].view(B,S,1).repeat([1, 1, nsample])\n",
    "        mask = group_idx == N\n",
    "        group_idx[mask] = group_first[mask]\n",
    "    \n",
    "        return group_idx\n",
    "    \n",
    "\n",
    "\n",
    "    def square_distance(self, src, dst):\n",
    "        B, N, _ = src.shape\n",
    "        _, M, _ = dst.shape\n",
    "        dist = -2 * torch.matmul(src, dst.permute(0, 2, 1))\n",
    "        dist += torch.sum(src ** 2, -1).view(B, N, 1)\n",
    "        dist += torch.sum(dst ** 2, -1).view(B, 1, M)\n",
    "        return dist\n",
    "\n",
    "\n",
    "class PointNetPlusPlus(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(PointNetPlusPlus, self).__init__()\n",
    "        self.sa1 = PointNetSetAbstraction(512, 0.2, 32, 3, [64, 64, 128], group_all=False)\n",
    "        self.sa2 = PointNetSetAbstraction(128, 0.4, 64, 128 +  3, [128, 128, 256], group_all=False)\n",
    "        self.sa3 = PointNetSetAbstraction(None, None, None, 256 + 3, [256, 512, 1024], group_all=True)\n",
    "        self.fc1 = nn.Linear(1024, 512)\n",
    "        self.bn1 = nn.BatchNorm1d(512)\n",
    "        self.drop1 = nn.Dropout(0.4)\n",
    "        self.fc2 = nn.Linear(512, 256)\n",
    "        self.bn2 = nn.BatchNorm1d(256)\n",
    "        self.drop2 = nn.Dropout(0.4)\n",
    "        self.fc3 = nn.Linear(256, num_classes)\n",
    "        #self.dropout = nn.Dropout(0.5)\n",
    "\n",
    "    def forward(self, xyz, points=None):\n",
    "        # xyz, points = self.sa1(xyz, points)\n",
    "        # xyz, points = self.sa2(xyz, points)\n",
    "        # _, points = self.sa3(xyz, points)\n",
    "        # x = points.view(points.size(0), -1)\n",
    "        # x = F.relu(self.bn1(self.fc1(x)))\n",
    "        # x = F.relu(self.bn2(self.dropout(self.fc2(x))))\n",
    "        # x = self.fc3(x)\n",
    "        # return F.log_softmax(x, dim=1)\n",
    "        B, _, _ = xyz.shape\n",
    "        \n",
    "        norm = xyz[:, 3:, :]\n",
    "        xyz = xyz[:, :3, :]\n",
    "        l1_xyz, l1_points = self.sa1(xyz, norm)\n",
    "        l2_xyz, l2_points = self.sa2(l1_xyz, l1_points)\n",
    "        l3_xyz, l3_points = self.sa3(l2_xyz, l2_points)\n",
    "        x = l3_points.view(B, 1024)\n",
    "        x = self.drop1(F.relu(self.bn1(self.fc1(x))))\n",
    "        x = self.drop2(F.relu(self.bn2(self.fc2(x))))\n",
    "        x = self.fc3(x)\n",
    "        x = F.log_softmax(x, -1)\n",
    "\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "52d770d2-e78e-4aed-9f9a-64e48d148538",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pointnetloss(outputs, labels, m3x3, m64x64, alpha = 0.0001):\n",
    "    criterion = torch.nn.NLLLoss()\n",
    "    bs=outputs.size(0)\n",
    "    id3x3 = torch.eye(3, requires_grad=True).repeat(bs,1,1)\n",
    "    id64x64 = torch.eye(64, requires_grad=True).repeat(bs,1,1)\n",
    "    if outputs.is_cuda:\n",
    "        id3x3=id3x3.cuda()\n",
    "        id64x64=id64x64.cuda()\n",
    "    diff3x3 = id3x3-torch.bmm(m3x3,m3x3.transpose(1,2))\n",
    "    diff64x64 = id64x64-torch.bmm(m64x64,m64x64.transpose(1,2))\n",
    "    return criterion(outputs, labels) + alpha * (torch.norm(diff3x3)+torch.norm(diff64x64)) / float(bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "74042981-3b55-4af9-9d08-c7594de0f7e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "191e5280-5f28-49f4-b07a-37059a77473b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(\"Input shape before first conv:\", points.shape)\n",
    "pointnet = PointNetPlusPlus(40)\n",
    "pointnet.to(device);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "81c704f0-36a6-49f7-a6aa-e71a8c049bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "#optimizer = torch.optim.Adam(pointnet.parameters(), lr=0.0008)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "40e8f932-4716-4ccb-a07a-f30a47cab519",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, val_loader=None, epochs=10):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        tqdm_bar = tqdm(enumerate(train_loader, 0), total=len(train_loader), desc=f\"Epoch {epoch+1}/{epochs}\")\n",
    "        \n",
    "        for i, data in tqdm_bar:\n",
    "            inputs, labels = data['pointcloud'].to(device).float(), data['category'].to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs.transpose(1, 2), points=None)\n",
    "            \n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            \n",
    "            train_acc = correct / total\n",
    "            tqdm_bar.set_postfix(loss=running_loss / (i + 1), train_acc=train_acc)\n",
    "        \n",
    "        final_train_acc = 100. * correct / total\n",
    "        final_train_loss = running_loss / len(train_loader)\n",
    "        \n",
    "        model.eval()\n",
    "        correct = total = 0\n",
    "        val_acc = 0\n",
    "        \n",
    "        if val_loader:\n",
    "            with torch.no_grad():\n",
    "                for data in val_loader:\n",
    "                    inputs, labels = data['pointcloud'].to(device).float(), data['category'].to(device)\n",
    "                    outputs = model(inputs.transpose(1, 2), points=None)\n",
    "                    _, predicted = torch.max(outputs.data, 1)\n",
    "                    total += labels.size(0)\n",
    "                    correct += (predicted == labels).sum().item()\n",
    "                val_acc = 100. * correct / total\n",
    "        \n",
    "        print(f'Epoch {epoch+1}/{epochs} | Train Loss: {final_train_loss:.3f} | Train Acc: {final_train_acc:.2f}% | Val Acc: {val_acc:.2f}%')\n",
    "        \n",
    "        torch.save(model.state_dict(), \"save_pointnetpp.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3171fbc4-eb33-4ed6-963f-226fa12ceecb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 308/308 [39:26<00:00,  7.68s/it, loss=1.8, train_acc=0.523]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 | Train Loss: 1.804 | Train Acc: 52.26% | Val Acc: 60.33%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 308/308 [44:16<00:00,  8.63s/it, loss=1.07, train_acc=0.685] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10 | Train Loss: 1.066 | Train Acc: 68.52% | Val Acc: 72.37%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 308/308 [50:47<00:00,  9.89s/it, loss=0.881, train_acc=0.736] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10 | Train Loss: 0.881 | Train Acc: 73.65% | Val Acc: 75.77%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 308/308 [53:18<00:00, 10.38s/it, loss=0.781, train_acc=0.76]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10 | Train Loss: 0.781 | Train Acc: 75.96% | Val Acc: 76.05%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 308/308 [52:34<00:00, 10.24s/it, loss=0.7, train_acc=0.781]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10 | Train Loss: 0.700 | Train Acc: 78.06% | Val Acc: 78.89%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 308/308 [43:45<00:00,  8.52s/it, loss=0.685, train_acc=0.786]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10 | Train Loss: 0.685 | Train Acc: 78.59% | Val Acc: 79.21%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 308/308 [40:45<00:00,  7.94s/it, loss=0.64, train_acc=0.798]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10 | Train Loss: 0.640 | Train Acc: 79.84% | Val Acc: 78.12%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/10:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 303/308 [37:15<00:32,  6.53s/it, loss=0.605, train_acc=0.809] "
     ]
    }
   ],
   "source": [
    "train(pointnet, train_loader, valid_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c20b390-42d2-47f1-b5af-31114692aac3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv.heimdall",
   "language": "python",
   "name": "venv.heimdall"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
